\section{Conclusion}
\label{sec:conclusion}
In the end, we summarize our findings concerning both hard cut and soft cut detection.

\subsection{Hard cut detection}
\label{sec:conclusion_hard_cut}

As we see in Table~\ref{tab:hard_cut_results}, the precision of our approach is the main problem. 
We have discussed the main reason for that in Section~\ref{sec:hard_cut_visualization}.
Our approach just takes two frames into account and therefore cannot notice, whether the transition under consideration is part of a noisy cluster or a single peak (see Figure~\ref{fig:hard_cut_noise_visualization}).
One idea to overcome this "blindness" is to use some surrounding histogram differences as additional features. The classifier is trained with a sliding window of histogram differences, resulting in specific patterns. The classification task would then be a pattern matching task, where hard-cuts are characterized by a single peak, soft-cuts by a gradual curve and noise by random peaks. Future work could also try to employ a neural net for this kind of pattern matching.
A different approach is to do post-processing.
To be continued.... ;)

\subsection{Soft cut detection}
\label{sec:conclusion_hard_cut}

What went wrong:
More data?

In summary.
We still think that the soft cut detection could be solved with deep learning.
However, the basic approach with using a recurrent neural network does not work.
More work and innovation is required in this area.

We think that the main problem is that the convolutional network cannot really learn good features, because there is nothing characteristic about a soft cut frame.
